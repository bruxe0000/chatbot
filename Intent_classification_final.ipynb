{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Dark-Sied/Intent_Classification/blob/master/Intent_classification_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a_WypuUXi92e",
    "outputId": "133d026e-4236-4ff6-f21d-739bfb9640db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LE6wywJrN2ih"
   },
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "#   df = pd.read_csv(filename, encoding = \"latin1\", names = [\"Sentence\", \"Intent\"])\n",
    "    df = pd.read_excel(filename, sheet_name=\"dataset_XY\", encoding=\"utf8\")\n",
    "    Label_tag = pd.read_excel(filename, sheet_name=\"Label_tag\", encoding=\"utf8\")  \n",
    "    print(df.head())\n",
    "    intent = df['Label']\n",
    "    for idx, i in enumerate(intent):\n",
    "#         print(i)\n",
    "        intent[idx] = Label_tag.loc[i,\"Tag\"]\n",
    "#     print(\"intent: \", intent)\n",
    "    unique_intent = list(set(intent))\n",
    "    sentences = list(df[\"Questions\"])\n",
    "  \n",
    "    return (intent, unique_intent, sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "tF0FQA7gjOCX",
    "outputId": "c609b42a-05da-49f5-8d11-bd670210f635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Questions  Label\n",
      "0               Chào      0\n",
      "1    Dạo này thế nào      0\n",
      "2  Có ai ở đây không      0\n",
      "3           Xin chào      0\n",
      "4           Xao chìn      0\n",
      "Unique intents:  ['Tạm_biệt', 'Chuẩn_bị_hồ_sơ', 'Cảm_ơn', 'Thời_gian_trả_kết_quả', 'Chức_năng_của_bot', 'Tên_bot', 'Nơi_nộp_hồ_sơ', 'Nơi_nhận_hộ_chiếu', 'Chào_hỏi', 'Thời_gian_giải_quyết_hộ_chiếu', 'Thời_gian_tiếp_nhận_hồ_sơ', 'Lệ_phí', 'Trình_tự ', 'Đối_tượng_xin_cấp_hộ_chiếu', 'Các_loại_hộ_chiếu']\n",
      "Number of intents:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Dell\\Anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "intent, unique_intent, sentences = load_dataset(\"dataset_XY_XLS_updatedbytho.xls\")\n",
    "print(\"Unique intents: \", unique_intent)\n",
    "print(\"Number of intents: \", len(unique_intent))\n",
    "# print(intent[:5])\n",
    "# len(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anh', 'thọ', 'quá', 'đẹp_trai', '!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hàm được viết bởi thọ\n",
    "import pyvi.ViTokenizer as viToken\n",
    "def viTokenList(word):\n",
    "    return viToken.tokenize(word).split()\n",
    "viTokenList(\"Anh thọ quá đẹp trai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O8LLUZlokg0S",
    "outputId": "c15c21dc-2ef2-43b7-b4af-e7ee9e014091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chào', 'Dạo này thế nào', 'Có ai ở đây không', 'Xin chào', 'Xao chìn']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "MhrziINPGHbW",
    "outputId": "0861af1b-4b82-4c92-b8f4-b6b57bb3e380"
   },
   "outputs": [],
   "source": [
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmNLu2YSXePb"
   },
   "outputs": [],
   "source": [
    "#define stemmer\n",
    "# stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-7q3iG5PKYI"
   },
   "outputs": [],
   "source": [
    "def cleaning(sentences):\n",
    "    words = []\n",
    "    for s in sentences:\n",
    "#         clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", s) # Find and replace duplicate \n",
    "        w = viTokenList(s)\n",
    "        #stemming\n",
    "        words.append([i.lower() for i in w])\n",
    "\n",
    "    return words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "p1j2GJgDG6qj",
    "outputId": "c7232a8e-6833-4a1d-e71a-4bc7014084a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "[['chào'], ['dạo', 'này', 'thế_nào']]\n"
     ]
    }
   ],
   "source": [
    "cleaned_words = cleaning(sentences)\n",
    "print(len(cleaned_words))\n",
    "print(cleaned_words[:2])  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJCQ_YhBJW7t"
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
    "    token = Tokenizer(filters = filters)\n",
    "    token.fit_on_texts(words)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJhdIJC5Q3Q6"
   },
   "outputs": [],
   "source": [
    "def max_length(words):\n",
    "    return(len(max(words, key = len)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JWjxPGsZZJNX",
    "outputId": "b02c8f6b-d0df-4e90-fa3a-2ff730c88300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size = 318 and Maximum length = 16\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = create_tokenizer(cleaned_words)\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "max_length = max_length(cleaned_words)\n",
    "\n",
    "print(\"Vocab Size = %d and Maximum length = %d\" % (vocab_size, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0TXu2xsR8jq"
   },
   "outputs": [],
   "source": [
    "def encoding_doc(token, words):\n",
    "    return(token.texts_to_sequences(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dE92Hk1Va--H"
   },
   "outputs": [],
   "source": [
    "encoded_doc = encoding_doc(word_tokenizer, cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fyOzLEboc4LZ"
   },
   "outputs": [],
   "source": [
    "def padding_doc(encoded_doc, max_length):\n",
    "    return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdejoJrlc-tc"
   },
   "outputs": [],
   "source": [
    "padded_doc = padding_doc(encoded_doc, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "gDgTCS2KdI2p",
    "outputId": "ac5332cd-0a0f-4311-8db4-22df92728d90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0],\n",
       "       [180,  99,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0],\n",
       "       [  5,  55,  24, 126,   3,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0],\n",
       "       [ 17, 115,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0],\n",
       "       [204,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3eaSIDi0dNf1",
    "outputId": "4ab6b6dd-ffa4-4061-9e9d-7a01decfa837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded docs =  (750, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded docs = \",padded_doc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0rXzenSpgFR"
   },
   "outputs": [],
   "source": [
    "#tokenizer with filter changed\n",
    "output_tokenizer = create_tokenizer(unique_intent, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "yNHQtkszskxr",
    "outputId": "f5babc01-89e3-4392-e8e6-c9f257de3d07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tạm_biệt': 1,\n",
       " 'chuẩn_bị_hồ_sơ': 2,\n",
       " 'cảm_ơn': 3,\n",
       " 'thời_gian_trả_kết_quả': 4,\n",
       " 'chức_năng_của_bot': 5,\n",
       " 'tên_bot': 6,\n",
       " 'nơi_nộp_hồ_sơ': 7,\n",
       " 'nơi_nhận_hộ_chiếu': 8,\n",
       " 'chào_hỏi': 9,\n",
       " 'thời_gian_giải_quyết_hộ_chiếu': 10,\n",
       " 'thời_gian_tiếp_nhận_hồ_sơ': 11,\n",
       " 'lệ_phí': 12,\n",
       " 'trình_tự': 13,\n",
       " 'đối_tượng_xin_cấp_hộ_chiếu': 14,\n",
       " 'các_loại_hộ_chiếu': 15}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OOx9qdBto1-"
   },
   "outputs": [],
   "source": [
    "encoded_output = encoding_doc(output_tokenizer, intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_5Lv5PiyG-z"
   },
   "outputs": [],
   "source": [
    "encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dpM86WrVQlx5",
    "outputId": "71ff52a6-b3d0-4b5c-850d-5dc0a56c8aa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rD3QN-RPzfet"
   },
   "outputs": [],
   "source": [
    "def one_hot(encode):\n",
    "    o = OneHotEncoder(sparse = False)\n",
    "    return(o.fit_transform(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6wP_Xed7RNR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "output_one_hot = one_hot(encoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A6HVslLTHgOM",
    "outputId": "752962df-02d8-409b-fb8f-adb06227161d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 15)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqABUESD7xi9"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8P4HTz6A4E-"
   },
   "outputs": [],
   "source": [
    "# print(len(padded_doc))\n",
    "# print(len(output_one_hot))\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7E0uhC2OCtTx",
    "outputId": "6ce0e215-aa3f-43f1-ba5a-0b584b25a35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X = (600, 16) and train_Y = (600, 15)\n",
      "Shape of val_X = (150, 16) and val_Y = (150, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
    "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5BU_x74DNEb"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 128, input_length = max_length, trainable = False))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    #   model.add(LSTM(128))\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(15, activation = \"softmax\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "f-NvE0P7MFCe",
    "outputId": "8f07056b-579e-4c15-e1af-bdfa8f681e79",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 16, 128)           40704     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                495       \n",
      "=================================================================\n",
      "Total params: 312,591\n",
      "Trainable params: 271,887\n",
      "Non-trainable params: 40,704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size, max_length)\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6834
    },
    "colab_type": "code",
    "id": "_r-dxm2sMQ-d",
    "outputId": "3c37b4f8-fc4e-4c82-ab46-2aa1d8b47ffd"
   },
   "outputs": [],
   "source": [
    "# filename = 'model.h5'\n",
    "# checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# hist = model.fit(train_X, train_Y, epochs = 300, batch_size = 32, validation_data = (val_X, val_Y), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjXKos8ocXvw"
   },
   "outputs": [],
   "source": [
    " model = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png', show_shapes=True,show_layer_names=True)\n",
    "# from IPython.display import display, Image\n",
    "# display(Image(filename='model.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot training & validation accuracy values\n",
    "# plt.plot(hist.history['acc'])\n",
    "# plt.plot(hist.history['val_acc'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot training & validation loss values\n",
    "# plt.plot(hist.history['loss'])\n",
    "# plt.plot(hist.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSTEzrlzcuya"
   },
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "#     clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", text)\n",
    "    test_word = viTokenList(text)\n",
    "    test_word = [w.lower() for w in test_word]\n",
    "    test_ls = word_tokenizer.texts_to_sequences(test_word)\n",
    "#     print(\"test_ls: \", test_ls)\n",
    "#     print(\"test_word: \", test_word)\n",
    "    #Check for unknown words\n",
    "    if [] in test_ls:\n",
    "        test_ls = list(filter(None, test_ls))\n",
    "\n",
    "    test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
    "\n",
    "    x = padding_doc(test_ls, max_length)\n",
    "\n",
    "    pred = model.predict_proba(x)\n",
    "\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_response_dataset(filename):\n",
    "    df_res = pd.read_excel(filename, sheet_name=\"Tag_Response\", encoding=\"utf8\") \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def response(classes):\n",
    "    df_res = load_response_dataset(\"dataset_XY_XLS_updatedbytho.xls\")\n",
    "    s = df_res[classes].dropna()\n",
    "    s_res = s[random.randint(0,len(s)-1)]\n",
    "    print(s_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1ddofshmdzK"
   },
   "outputs": [],
   "source": [
    "def get_final_output(pred, classes):\n",
    "    predictions = pred[0]\n",
    "\n",
    "    classes = np.array(classes)\n",
    "    ids = np.argsort(-predictions)\n",
    "    classes = classes[ids]\n",
    "    predictions = -np.sort(-predictions)\n",
    " \n",
    "    for i in range(3):\n",
    "        print(\"%s has confidence = %s\" % (classes[i], (predictions[i])))\n",
    "    response(classes[0])\n",
    "#     print(classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "23VpGuihMdEU",
    "outputId": "cd36c932-0fb0-4166-92ae-546a7676e645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "Chức_năng_của_bot has confidence = 0.7883284\n",
      "Nơi_nộp_hồ_sơ has confidence = 0.14198619\n",
      "Thời_gian_giải_quyết_hộ_chiếu has confidence = 0.039299227\n",
      "Tôi là Chatbot hỗ trợ bạn trong việc tư vấn về thủ tục Hành Chính Công, cụ thể là về thủ tục passport. Có hai loại hộ chiếu là hộ chiếu cấp Trung ương và cấp tỉnh. Bạn nên lưu ý ghi rõ là cấp nào.\n",
      "ngu luôn\n",
      "Chức_năng_của_bot has confidence = 0.55176234\n",
      "Thời_gian_giải_quyết_hộ_chiếu has confidence = 0.34406018\n",
      "Tên_bot has confidence = 0.07534421\n",
      "Tôi là Chatbot hỗ trợ bạn trong việc tư vấn về thủ tục Hành Chính Công, cụ thể là về thủ tục passport. Có hai loại hộ chiếu là hộ chiếu cấp Trung ương và cấp tỉnh. Bạn nên lưu ý ghi rõ là cấp nào.\n",
      "sao m bị ngu rồi?\n",
      "Chức_năng_của_bot has confidence = 0.54097444\n",
      "Thời_gian_giải_quyết_hộ_chiếu has confidence = 0.3523135\n",
      "Tên_bot has confidence = 0.07309757\n",
      "Tôi là Chatbot hỗ trợ bạn trong việc tư vấn về thủ tục Hành Chính Công, cụ thể là về thủ tục passport. Có hai loại hộ chiếu là hộ chiếu cấp Trung ương và cấp tỉnh. Bạn nên lưu ý ghi rõ là cấp nào.\n",
      "hộ chiếu\n",
      "Chức_năng_của_bot has confidence = 0.55176234\n",
      "Thời_gian_giải_quyết_hộ_chiếu has confidence = 0.34406018\n",
      "Tên_bot has confidence = 0.07534421\n",
      "Tôi là Chatbot hỗ trợ bạn trong việc tư vấn về thủ tục Hành Chính Công, cụ thể là về thủ tục passport. Có hai loại hộ chiếu là hộ chiếu cấp Trung ương và cấp tỉnh. Bạn nên lưu ý ghi rõ là cấp nào.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while(1):\n",
    "    text = input()    \n",
    "    if text == 'q':\n",
    "        break\n",
    "    pred = predictions(text)\n",
    "    get_final_output(pred, unique_intent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKUBDT36IHKO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Intent_classification_final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
